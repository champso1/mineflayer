{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#module importing and class definitions\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from PIL import ImageOps\n",
    "import os\n",
    "\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.transforms import ToTensor\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "class CustomImageDataset(Dataset):\n",
    "    def __init__(self, annotations_file, img_dir, transform=None, target_transform=None):\n",
    "        self.img_labels = pd.read_csv(annotations_file)\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_labels)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img_path = os.path.join(self.img_dir, self.img_labels.iloc[idx, 0])\n",
    "        image = Image.open(img_path)        #PIL image opener\n",
    "        image = ImageOps.grayscale(image)   #convert to grayscale to follow tutorial\n",
    "        #image = pil_to_tensor(image)\n",
    "        label = self.img_labels.iloc[idx, 1]\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        if self.target_transform:\n",
    "            label = self.target_transform(label)\n",
    "\n",
    "        return image, label\n",
    "\n",
    "\n",
    "\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(128*72, 128*72),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128*72, 1028),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(1028, 1028),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(1028, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 2)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating the dataloaders and instance of the network\n",
    "img_dir = './all_frames/'\n",
    "training_data = CustomImageDataset('training.csv', img_dir, transform=ToTensor())\n",
    "testing_data = CustomImageDataset('testing.csv', img_dir, transform=ToTensor())\n",
    "\n",
    "train_dataloader = DataLoader(training_data, batch_size=64, shuffle=True)\n",
    "testing_dataloader = DataLoader(testing_data, batch_size=64, shuffle=True)\n",
    "\n",
    "model = NeuralNetwork()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#testing\n",
    "train_features, train_labels = next(iter(train_dataloader))\n",
    "print(f\"Feature batch shape: {train_features.size()}\")\n",
    "print(f\"Labels batch shape: {train_labels.size()}\")\n",
    "img = train_features[0].squeeze()\n",
    "label = train_labels[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------\n",
      "loss: 0.698549  [   64/ 1374]\n",
      "loss: 0.693754  [  704/ 1374]\n",
      "loss: 0.685834  [ 1344/ 1374]\n",
      "Test Error: \n",
      " Accuracy: 54.8%, Avg loss: 0.688687 \n",
      "\n",
      "Epoch 2\n",
      "-------------------\n",
      "loss: 0.687853  [   64/ 1374]\n",
      "loss: 0.689237  [  704/ 1374]\n",
      "loss: 0.689889  [ 1344/ 1374]\n",
      "Test Error: \n",
      " Accuracy: 54.8%, Avg loss: 0.688846 \n",
      "\n",
      "Epoch 3\n",
      "-------------------\n",
      "loss: 0.680543  [   64/ 1374]\n",
      "loss: 0.687862  [  704/ 1374]\n",
      "loss: 0.696640  [ 1344/ 1374]\n",
      "Test Error: \n",
      " Accuracy: 54.8%, Avg loss: 0.687426 \n",
      "\n",
      "Epoch 4\n",
      "-------------------\n",
      "loss: 0.690059  [   64/ 1374]\n",
      "loss: 0.689064  [  704/ 1374]\n",
      "loss: 0.683949  [ 1344/ 1374]\n",
      "Test Error: \n",
      " Accuracy: 54.8%, Avg loss: 0.688548 \n",
      "\n",
      "Epoch 5\n",
      "-------------------\n",
      "loss: 0.689210  [   64/ 1374]\n",
      "loss: 0.689697  [  704/ 1374]\n",
      "loss: 0.682153  [ 1344/ 1374]\n",
      "Test Error: \n",
      " Accuracy: 54.8%, Avg loss: 0.685660 \n",
      "\n",
      "Epoch 6\n",
      "-------------------\n",
      "loss: 0.685078  [   64/ 1374]\n",
      "loss: 0.685436  [  704/ 1374]\n",
      "loss: 0.695085  [ 1344/ 1374]\n",
      "Test Error: \n",
      " Accuracy: 54.8%, Avg loss: 0.689533 \n",
      "\n",
      "Epoch 7\n",
      "-------------------\n",
      "loss: 0.688689  [   64/ 1374]\n",
      "loss: 0.694105  [  704/ 1374]\n",
      "loss: 0.680172  [ 1344/ 1374]\n",
      "Test Error: \n",
      " Accuracy: 54.8%, Avg loss: 0.687989 \n",
      "\n",
      "Epoch 8\n",
      "-------------------\n",
      "loss: 0.677401  [   64/ 1374]\n",
      "loss: 0.684317  [  704/ 1374]\n",
      "loss: 0.686200  [ 1344/ 1374]\n",
      "Test Error: \n",
      " Accuracy: 54.8%, Avg loss: 0.685485 \n",
      "\n",
      "Epoch 9\n",
      "-------------------\n",
      "loss: 0.683458  [   64/ 1374]\n",
      "loss: 0.684447  [  704/ 1374]\n",
      "loss: 0.685150  [ 1344/ 1374]\n",
      "Test Error: \n",
      " Accuracy: 54.8%, Avg loss: 0.684795 \n",
      "\n",
      "Epoch 10\n",
      "-------------------\n",
      "loss: 0.685722  [   64/ 1374]\n",
      "loss: 0.674075  [  704/ 1374]\n",
      "loss: 0.706491  [ 1344/ 1374]\n",
      "Test Error: \n",
      " Accuracy: 54.8%, Avg loss: 0.686421 \n",
      "\n",
      "Epoch 11\n",
      "-------------------\n",
      "loss: 0.688074  [   64/ 1374]\n",
      "loss: 0.685605  [  704/ 1374]\n",
      "loss: 0.687279  [ 1344/ 1374]\n",
      "Test Error: \n",
      " Accuracy: 54.8%, Avg loss: 0.684497 \n",
      "\n",
      "Epoch 12\n",
      "-------------------\n",
      "loss: 0.687199  [   64/ 1374]\n",
      "loss: 0.689052  [  704/ 1374]\n",
      "loss: 0.687116  [ 1344/ 1374]\n",
      "Test Error: \n",
      " Accuracy: 54.8%, Avg loss: 0.685443 \n",
      "\n",
      "Epoch 13\n",
      "-------------------\n",
      "loss: 0.688773  [   64/ 1374]\n",
      "loss: 0.671456  [  704/ 1374]\n",
      "loss: 0.689792  [ 1344/ 1374]\n",
      "Test Error: \n",
      " Accuracy: 54.8%, Avg loss: 0.684403 \n",
      "\n",
      "Epoch 14\n",
      "-------------------\n",
      "loss: 0.691516  [   64/ 1374]\n",
      "loss: 0.683555  [  704/ 1374]\n",
      "loss: 0.675670  [ 1344/ 1374]\n",
      "Test Error: \n",
      " Accuracy: 54.8%, Avg loss: 0.686244 \n",
      "\n",
      "Epoch 15\n",
      "-------------------\n",
      "loss: 0.686991  [   64/ 1374]\n",
      "loss: 0.678113  [  704/ 1374]\n",
      "loss: 0.692614  [ 1344/ 1374]\n",
      "Test Error: \n",
      " Accuracy: 54.8%, Avg loss: 0.683090 \n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "#training and testing loops\n",
    "\n",
    "def train_loop(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    model.train()\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        # Compute prediction and loss\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        # Backpropagation\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        if batch % 10 == 0:\n",
    "            loss, current = loss.item(), (batch + 1) * len(X)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
    "\n",
    "\n",
    "def test_loop(dataloader, model, loss_fn):\n",
    "    model.eval()\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    test_loss, correct = 0, 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (torch.argmax(pred, 1) == y).type(torch.float).sum().item()\n",
    "\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")\n",
    "\n",
    "\n",
    "learning_rate = 1e-3\n",
    "epochs = 15\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "\n",
    "for t in range(epochs):\n",
    "    print(f'Epoch {t+1}\\n-------------------')\n",
    "    train_loop(train_dataloader, model, loss_fn, optimizer)\n",
    "    test_loop(testing_dataloader, model, loss_fn)\n",
    "\n",
    "print('Done!')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
